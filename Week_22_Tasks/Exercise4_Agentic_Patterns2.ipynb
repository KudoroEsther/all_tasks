{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3f4fef",
   "metadata": {},
   "source": [
    "# Exercise 2: Plan-Execute + Reflection Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0ce55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal, TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import os\n",
    "import operator\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f13acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"paid_api2\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API_Key not found. Please set it in your .env file\")\n",
    "print(\"API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d965f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "## Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key = api_key\n",
    ")\n",
    "print(f\"LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b1221",
   "metadata": {},
   "source": [
    "## Plan-Execute Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1991ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid state defined\n"
     ]
    }
   ],
   "source": [
    "#Customized state for plan-execute\n",
    "class HybridState(TypedDict):\n",
    "    \"\"\"State for hybrid pattern combining plan-execute and reflection pattern.\"\"\"\n",
    "    #Plan-execute\n",
    "    input: str \n",
    "    plan: list[str]\n",
    "    current_step: int\n",
    "    results: Annotated[list[str], operator.add] #Results from each step\n",
    "    \n",
    "    #Reflection pattern\n",
    "    iterations: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    final_output: str\n",
    "\n",
    "MAX_ITERATIONS =2\n",
    "print(\"Hybrid state defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3df0e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Node 1: Planner\n",
    "def planner(state: HybridState) -> dict:\n",
    "    \"\"\"Create a step-by-step plan.\"\"\"\n",
    "    prompt = f\"\"\"Create a step-by-step plan for this task:\n",
    "\n",
    "Task: {state['input']}\n",
    "\n",
    "Return a numbered list of 3 concrete steps. Keep it simple.\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    # Parse steps (simple parsing)\n",
    "    lines = response.content.split('\\n')\n",
    "    steps = [line.strip() for line in lines if line.strip() and any(char.isdigit() for char in line[:3])]\n",
    "\n",
    "    # print(lines)\n",
    "    print(f\"\\nPLAN CREATED:\")\n",
    "    for step in steps:\n",
    "        print(f\"    {step}\")\n",
    "    print()\n",
    "\n",
    "    return {\"plan\": steps, \"current_step\": 0, \"results\": []}\n",
    "\n",
    "# Node 2: Executor\n",
    "def executor(state: HybridState) -> dict:\n",
    "    \"\"\"Execute current step.\"\"\"\n",
    "    if state[\"current_step\"] >= len(state[\"plan\"]):\n",
    "        #All steps done\n",
    "        return {}\n",
    "    \n",
    "    current_step = state[\"plan\"][state[\"current_step\"]] #maps current step to a planned task\n",
    "\n",
    "    print(f\"Executing: {current_step}\")\n",
    "\n",
    "    # Execute step (simplified - just use LLM)\n",
    "    prompt = f\"\"\"Previous results: {state.get('results', [])}\\n\\nExecute this step: {current_step}\"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    result = f\"Step {state['current_step']+1} result: {response.content}\"\n",
    "    # print(result)\n",
    "    print(f\"âœ“ Done\\n\")\n",
    "\n",
    "    return {\n",
    "        \"results\": [result],\n",
    "        \"current_step\": state[\"current_step\"]+1\n",
    "    }\n",
    "\n",
    "# print(\"Plan-Execute nodes defined\")\n",
    "\n",
    "#Node Generator\n",
    "def generator(state: HybridState) -> dict:\n",
    "    \"\"\"Synthesizes all execution results into a final draft.\"\"\"\n",
    "    print(\"\\nSynthesizing execution results into a draft...\")\n",
    "\n",
    "    prompt = f\"\"\"Synthesize these research results into a final answer for the user.\n",
    "Original Task: {state['input']}\n",
    "Research Results: {state['results']}\n",
    "    \n",
    "Ensure the response is comprehensive, direct. and beginner-friendly.\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\n",
    "        \"draft\": response.content,\n",
    "        \"iterations\": 0\n",
    "    }\n",
    "\n",
    "#Node Critic\n",
    "def critic(state: HybridState) -> dict:\n",
    "    \"\"\"Evaluates the draft and suggests improvements.\"\"\"\n",
    "    print(\"Critiquing draft for quality and beginner-friendliness...\")\n",
    "\n",
    "    prompt = f\"\"\"Evaluate this draft against the original task.\n",
    "Task: {state['input']}\n",
    "Draft: {state['draft']}\n",
    "    \n",
    "Critique it for:\n",
    "1. It's research quality\n",
    "2. Tone (must be beginner-friendly)\n",
    "3. Clarity and engagement\n",
    "    \n",
    "If it is excellent, say 'APPROVED: explanation'. \n",
    "Otherwise, list specific improvements needed.\"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\n",
    "        \"critique\": response.content,\n",
    "        \"iterations\": state[\"iterations\"] + 1\n",
    "    }\n",
    "\n",
    "# Node refiner\n",
    "def refiner(state: HybridState) -> dict:\n",
    "    \"\"\"Refines the draft based on the critic's feedback.\"\"\"\n",
    "    print(f\"Refining draft (Iteration {state['iterations']})...\")\n",
    "\n",
    "    prompt = f\"\"\"Refine the draft below using the provided critique.\n",
    "Original Task: {state['input']}\n",
    "Current Draft: {state['draft']}\n",
    "Critique: {state['critique']}\n",
    "    \n",
    "Provide an improved, high-quality version.\"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"draft\": response.content}\n",
    "\n",
    "def finalizer(state: HybridState) -> dict:\n",
    "    \"\"\"Returns the final refiined output.\"\"\"\n",
    "    print(\"\\nHybrid process complete!\")\n",
    "    return {\n",
    "        \"final_output\": state[\"draft\"]}\n",
    "\n",
    "print(\"All nodes defined\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215df55",
   "metadata": {},
   "source": [
    "### Routing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b2740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing functions defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue_execution(state: HybridState) -> Literal[\"executor\", \"generator\"]:\n",
    "    \"\"\"Decide if there are more steps to be executed.\"\"\"\n",
    "    if state[\"current_step\"] < len(state[\"plan\"]):\n",
    "        return \"executor\"\n",
    "    return \"generator\"\n",
    "\n",
    "def should_reflect_again(state: HybridState) -> Literal[\"refiner\", \"finalizer\"]:\n",
    "    \"\"\"Decide if further refinement is needed.\"\"\"\n",
    "    if \"APPROVED\" in state.get(\"critique\", \"\").upper():\n",
    "        return \"finalizer\"\n",
    "    \n",
    "    if state[\"iterations\"] >= MAX_ITERATIONS:\n",
    "        print(f\"Max reflections ({MAX_ITERATIONS})reached.\")\n",
    "        return \"finalizer\"\n",
    "    \n",
    "    return \"refiner\"\n",
    "\n",
    "print(\"Routing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8391a",
   "metadata": {},
   "source": [
    "### Hybrid Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0801cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Graph compiled\n"
     ]
    }
   ],
   "source": [
    "hybrid_builder = StateGraph(HybridState)\n",
    "\n",
    "# Add nodes\n",
    "hybrid_builder.add_node(\"planner\", planner)\n",
    "hybrid_builder.add_node(\"executor\", executor)\n",
    "hybrid_builder.add_node(\"generator\", generator)\n",
    "hybrid_builder.add_node(\"critic\", critic)\n",
    "hybrid_builder.add_node(\"refiner\", refiner)\n",
    "hybrid_builder.add_node(\"finalizer\", finalizer)\n",
    "\n",
    "#Add edges\n",
    "hybrid_builder.add_edge(START, \"planner\")\n",
    "hybrid_builder.add_edge(\"planner\", \"executor\")\n",
    "\n",
    "hybrid_builder.add_conditional_edges(\n",
    "    \"executor\", should_continue_execution,\n",
    "    {\"executor\": \"executor\", \"generator\": \"generator\"}\n",
    ")\n",
    "\n",
    "hybrid_builder.add_edge(\"generator\", \"critic\")\n",
    "hybrid_builder.add_conditional_edges(\n",
    "    \"critic\", should_reflect_again,\n",
    "    {\"refiner\": \"refiner\", \"finalizer\": \"finalizer\"}\n",
    ")\n",
    "hybrid_builder.add_edge(\"refiner\", \"critic\")\n",
    "hybrid_builder.add_edge(\"finalizer\", END)\n",
    "\n",
    "hybrid_agent = hybrid_builder.compile()\n",
    "\n",
    "print(\"Hybrid Graph compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4977dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PLAN CREATED:\n",
      "    1. **Conduct Research on Python Benefits**:\n",
      "    2. **Summarize Key Points**:\n",
      "    3. **Create a Beginner-Friendly Summary**:\n",
      "\n",
      "Executing: 1. **Conduct Research on Python Benefits**:\n",
      "âœ“ Done\n",
      "\n",
      "Executing: 2. **Summarize Key Points**:\n",
      "âœ“ Done\n",
      "\n",
      "Executing: 3. **Create a Beginner-Friendly Summary**:\n",
      "âœ“ Done\n",
      "\n",
      "\n",
      "Synthesizing execution results into a draft...\n",
      "Critiquing draft for quality and beginner-friendliness...\n",
      "\n",
      "Hybrid process complete!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“Š FINAL OUTPUT:\n",
      "======================================================================\n",
      "**Why Choose Python?**\n",
      "\n",
      "Python is a fantastic programming language, especially if you're just starting out. Hereâ€™s a beginner-friendly summary of its many benefits:\n",
      "\n",
      "1. **Easy to Learn**: Python has a simple and clear syntax, which makes it perfect for beginners. You can grasp programming concepts quickly without getting bogged down by complicated rules.\n",
      "\n",
      "2. **Versatile**: You can use Python for a wide range of applications, including building websites, analyzing data, creating machine learning models, and automating tasks. This versatility makes it valuable in many fields.\n",
      "\n",
      "3. **Built-In Tools**: Python comes with a lot of built-in functions and libraries that help you perform common tasks without needing to search for additional tools. This means you can get started right away without extra hassle.\n",
      "\n",
      "4. **Supportive Community**: Thereâ€™s a large community of Python users, so finding help, tutorials, and resources online is easy. Whether you have questions or need guidance, youâ€™re never alone.\n",
      "\n",
      "5. **Many Libraries Available**: Python has countless libraries that add extra features, making it easier to work in specific areas like data science or web development. These libraries save you time and effort.\n",
      "\n",
      "6. **Works on Any System**: Python programs can run on various operating systems, including Windows, macOS, and Linux. This cross-platform compatibility means you donâ€™t have to worry about whether your code will work on different computers.\n",
      "\n",
      "7. **In Demand**: Many companies are actively looking for Python developers, especially in technology-related jobs. Learning Python can open up numerous career opportunities.\n",
      "\n",
      "8. **Integrates Well**: Python can easily work alongside other programming languages, making it flexible for various projects. If youâ€™re working in a mixed-language environment, Python can fit in seamlessly.\n",
      "\n",
      "9. **Multiple Programming Styles**: Python supports different programming styles, such as object-oriented and functional programming. This flexibility allows you to choose the approach that best suits your project.\n",
      "\n",
      "10. **Fast Prototyping**: You can quickly build and test your ideas with Python, which helps bring new products to market faster. This speed is crucial for innovation and development.\n",
      "\n",
      "11. **Great for Data**: Python has powerful tools for data manipulation and analysis, making it a favorite among data scientists. Libraries like Pandas and NumPy make working with data straightforward.\n",
      "\n",
      "12. **Testing Made Easy**: Python provides tools to help you check your code for errors, ensuring it works correctly. This focus on quality helps you build reliable applications.\n",
      "\n",
      "In summary, Python is an excellent choice for anyone looking to start programming or for experienced developers seeking a flexible and powerful language. Its simplicity, versatility, and strong community support make it a top pick for a wide range of programming tasks!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Research the benefits of Python programming, create a summary, and make it beginner-friendly\"\n",
    "\n",
    "result = hybrid_agent.invoke({\n",
    "    \"input\": query,\n",
    "    \"plan\": [],\n",
    "    \"current_step\": 0,\n",
    "    \"results\": [],\n",
    "    \"iterations\": 0,\n",
    "    \"critique\": \"\",\n",
    "    \"draft\": \"\"\n",
    "    \n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ðŸ“Š FINAL OUTPUT:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(result[\"final_output\"])\n",
    "print(f\"{'='*70}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
