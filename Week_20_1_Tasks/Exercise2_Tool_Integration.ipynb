{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0154a7",
   "metadata": {},
   "source": [
    "# Practice Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8917a1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "018c8f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "import re\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92681bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('paid_api')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found!\")\n",
    "print(\"API Key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fbe2ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    temperature = 0.7,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8ee6b",
   "metadata": {},
   "source": [
    "## Creating Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70cc0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather tool defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@ tool\n",
    "def weather_tool(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns simulated weather for a given city.\n",
    "    Use this tool when the weather of a given city is required.\n",
    "\n",
    "    Args:\n",
    "        city: The given city\n",
    "    \n",
    "    Returns:\n",
    "        A simulated weather for the city\n",
    "    \"\"\"\n",
    "\n",
    "    def simulate_weather(city: str) ->dict:\n",
    "        \"\"\"\n",
    "        Generate deterministic fake weather data for a city.\n",
    "        \"\"\"\n",
    "        random.seed(city.lower())\n",
    "\n",
    "        conditions = [\"Sunny\", \"Cloudy\", \"Rainy\", \"Thunderstorm\", \"Hazy\"]\n",
    "        \n",
    "        return {\n",
    "            \"city\": city.title(),\n",
    "            \"temperature_c\": random.randint(22, 36),\n",
    "            \"condition\": random.choice(conditions),\n",
    "            \"humidity_percent\": random.randint(40, 90)\n",
    "        }\n",
    "    \n",
    "    weather = simulate_weather(city)\n",
    "    return (\n",
    "        f\"Weather in {weather['city']}:\\n\"\n",
    "        f\"- Temperature: {weather['temperature_c']}°C\\n\"\n",
    "        f\"- Condition: {weather['condition']}\\n\"\n",
    "        f\"- Humidity: {weather['humidity_percent']}%\"\n",
    "    )\n",
    "print(\"Weather tool defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b224a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary tool defined\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def dictionary(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Accepts a question and returns a definition from a simulated dictionary.\n",
    "\n",
    "    Example inputs:\n",
    "    - \"What is the meaning of agent?\"\n",
    "    - \"Define RAG\"\n",
    "    - \"What does embedding mean?\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulated dictionary\n",
    "    dictionary = {\n",
    "        \"agent\": \"An entity that perceives its environment and acts upon it.\",\n",
    "        \"tool\": \"A function or capability an agent can use to perform a task.\",\n",
    "        \"rag\": \"Retrieval-Augmented Generation, combining retrieval with generation.\",\n",
    "        \"llm\": \"Large Language Model trained on vast amounts of text data.\",\n",
    "        \"embedding\": \"A numerical representation of text capturing semantic meaning.\",\n",
    "        \"help\": \"To give assistance or support to (someone)\"\n",
    "    }\n",
    "\n",
    "    # Normalize question\n",
    "    word = question.lower().strip()\n",
    "\n",
    "\n",
    "    # Lookup\n",
    "    if word in dictionary:\n",
    "        return f\"{word.title()}: {dictionary[word]}\"\n",
    "    else:\n",
    "        return f\"{word.title()}: Definition not found in the simulated dictionary.\"\n",
    "print(\"Dictionary tool defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8401779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web search tool defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the web using DuckDuckGo and returns summarized results.\n",
    "\n",
    "    Example inputs:\n",
    "    - \"Latest news on AI\"\n",
    "    - \"What is LangGraph?\"\n",
    "    - \"Weather patterns in Nigeria\"\n",
    "    \"\"\"\n",
    "\n",
    "    results_text = []\n",
    "\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(\n",
    "            query,\n",
    "            region=\"wt-wt\",\n",
    "            safesearch=\"moderate\",\n",
    "            max_results=5\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            title = r.get(\"title\", \"No title\")\n",
    "            snippet = r.get(\"body\", \"No summary\")\n",
    "            source = r.get(\"href\", \"No link\")\n",
    "\n",
    "            results_text.append(\n",
    "                f\"Title: {title}\\n\"\n",
    "                f\"Summary: {snippet}\\n\"\n",
    "                f\"Source: {source}\\n\"\n",
    "            )\n",
    "\n",
    "    if not results_text:\n",
    "        return \"No results found.\"\n",
    "\n",
    "    return \"\\n---\\n\".join(results_text)\n",
    "print(\"Web search tool defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b3a06",
   "metadata": {},
   "source": [
    "## Binding tools to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3588f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM bound to 3 tools\n",
      "Tools: ['weather_tool', 'dictionary', 'web_search']\n"
     ]
    }
   ],
   "source": [
    "tools= [weather_tool, dictionary, web_search]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "print(f\"LLM bound to {len(tools)} tools\")\n",
    "print(f\"Tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4654a1",
   "metadata": {},
   "source": [
    "## Defining the Assistant Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ce2fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant mode defined\n"
     ]
    }
   ],
   "source": [
    "sys_msg = SystemMessage(content=\"\"\"You are a helpful assitant with access to tools.\n",
    "When asked to perform for the weather, use the weather tool.\n",
    "When asked to define something, use the dictionary tool.\n",
    "When asked to search the internet, use the web search tool.\n",
    "\n",
    "Only use tools when necessary - for simple questions, answer directly.\"\"\")\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to use tools or answer directly.\n",
    "    \"\"\"\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"Assistant mode defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be3418",
   "metadata": {},
   "source": [
    "## Implementing Conditional Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "434e297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: MessagesState)-> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide next step based on last message.\n",
    "    \n",
    "    If LLM called a tool → go to 'tools' node\n",
    "    If LLM provided final answer → go to END\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # check if LLM made tool calls\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "print(\"Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c227f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent graph compiled with tools and memory\n"
     ]
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "agent= builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Agent graph compiled with tools and memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc758e3",
   "metadata": {},
   "source": [
    "## The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9dd2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_agent(user_input: str, thread_id: str = \"test6\"):\n",
    "    \"\"\"\n",
    "    Run the agent and display the conversation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"User: {user_input}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "\n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            continue\n",
    "        elif isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                print(f\"\\nAgent: [Calling tool: {message.tool_calls[0][\"name\"]}]\")\n",
    "            else:\n",
    "                print(f\"\\nAgent: {message.content}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"\\nTool Result: {message.content[:50]}...\")\n",
    "    print(f\"\\n{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "023d2bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "User: What is the weather in Ogun?\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Agent: [Calling tool: weather_tool]\n",
      "\n",
      "Tool Result: Weather in Ogun:\n",
      "- Temperature: 27°C\n",
      "- Condition: ...\n",
      "\n",
      "Agent: The weather in Ogun is currently 27°C, cloudy, with a humidity level of 52%.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_agent(\"What is the weather in Ogun?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46c6ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "User: What is the capital of Vietnam?\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Agent: [Calling tool: weather_tool]\n",
      "\n",
      "Tool Result: Weather in Ogun:\n",
      "- Temperature: 27°C\n",
      "- Condition: ...\n",
      "\n",
      "Agent: The weather in Ogun is currently 27°C, cloudy, with a humidity level of 52%.\n",
      "\n",
      "Agent: The capital of Vietnam is Hanoi.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_agent(\"What is the capital of Vietnam?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
