{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3ce8be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported sucessfully\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "print(\"Libraries imported sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b509cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dbb85",
   "metadata": {},
   "source": [
    "# Exercise 1: Understanding Embedding Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa9734",
   "metadata": {},
   "source": [
    "2. Generate embeddings for all sentences using `all-MiniLM-L6-v2`\n",
    "\n",
    "3. Calculate similarity scores between:\n",
    "   - Sentence 1 and all others\n",
    "   - Sentence 4 and all others\n",
    "\n",
    "4. Answer these questions:\n",
    "   - Which sentences are most similar to \"The dog is playing in the park\"?\n",
    "   - Which sentences are most similar to \"Python is a programming language\"?\n",
    "   - What similarity threshold would you use to filter unrelated content?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6da5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Returns a score between -1 and 1 (higher = more similar)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a21a8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The dog is playing in the park\",\n",
    "    \"A puppy is running outside\",\n",
    "    \"The cat is sleeping on the couch\",\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning models need data\",\n",
    "    \"I love coding in Python\"\n",
    "]\n",
    "\n",
    "# generating embeddings for the given sentences\n",
    "embedding = model.encode(sentences)\n",
    "\n",
    "def compute_similarity(query_index):\n",
    "    query_sentence = sentences[query_index]\n",
    "    query_embedding = embedding[query_index]\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        score = cosine_similarity(query_embedding, embedding[i])\n",
    "        similarities.append((sentence, score))\n",
    "\n",
    "    # Sort by similarity score (descending)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # for senten, score in similarities:\n",
    "    #     print(f\"{score:.4f} \\n{senten}\")\n",
    "    #     print(\"-\" * 60)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74cc01ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"The dog is playing in the park\"\n",
      "Most similar: A puppy is running outside\n",
      "Least similar: Machine learning models need data\n",
      "\n",
      "Query: \"Python is a programming language\"\n",
      "Most similar: I love coding in Python\n",
      "Least similar: The cat is sleeping on the couch\n"
     ]
    }
   ],
   "source": [
    "sentence1 = compute_similarity(query_index=0)\n",
    "sentence4 = compute_similarity(query_index=3)\n",
    "\n",
    "print(f'Query: \"{sentences[0]}\"')\n",
    "print(f\"Most similar: {sentence1[1][0]}\")\n",
    "print(f\"Least similar: {sentence1[-1][0]}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(f'Query: \"{sentences[3]}\"')\n",
    "print(f\"Most similar: {sentence4[1][0]}\")\n",
    "print(f\"Least similar: {sentence4[-1][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa534c",
   "metadata": {},
   "source": [
    "I would choose a similarity threshold of 0.3 to filter out unrelated content, as chunks with similarity scores <0.3 are unrelated to the query <br>\n",
    "\n",
    "Recommended similarity threshold: 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1733eed",
   "metadata": {},
   "source": [
    "# Exercise2: Chunk Size Impact on Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
    "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "the field as the study of intelligent agents: any device that perceives its environment\n",
    "and takes actions that maximize its chance of successfully achieving its goals.\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that focuses on the use of data\n",
    "and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "Machine learning is an important component of the growing field of data science.\n",
    "\n",
    "Deep learning is part of a broader family of machine learning methods based on artificial\n",
    "neural networks with representation learning. Learning can be supervised, semi-supervised\n",
    "or unsupervised. Deep learning architectures such as deep neural networks, deep belief\n",
    "networks, recurrent neural networks and convolutional neural networks have been applied\n",
    "to fields including computer vision, speech recognition, natural language processing,\n",
    "machine translation, and bioinformatics.\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language, in\n",
    "particular how to program computers to process and analyze large amounts of natural\n",
    "language data. Challenges in natural language processing frequently involve speech\n",
    "recognition, natural language understanding, and natural language generation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef54aa",
   "metadata": {},
   "source": [
    "Save the various chunk sizes in multiple variable of single variable e.g sizes = 100, 200, 300\n",
    "write a function that chunks, saves , and embeds each chunk size\n",
    "Compare the query embedding to each chunk embedding, retrieve top 3 chunks from each comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0678e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_chunk, medium_chunk, large_chunk = 100, 200, 400\n",
    "\n",
    "# def chunk_embed(document, chunk_size, overlap=20):\n",
    "#     chunks = []\n",
    "#     start = 0\n",
    "\n",
    "#     #Character chunking\n",
    "#     while start < len(document):\n",
    "#         end = start + chunk_size\n",
    "#         chunk = document[start:end]\n",
    "#         chunks.append(chunk)\n",
    "#         start +=chunk_size-overlap\n",
    "    \n",
    "\n",
    "#     # word chunking\n",
    "#     # words = document.split()\n",
    "#     # for i in range(0, len(words), chunk_size):\n",
    "#     #     chunk = ' '.join(words[i:i+chunk_size])\n",
    "#     #     chunks.append(chunk)\n",
    "#     return chunks\n",
    "\n",
    "def chunk_embed_retrieve(document, chunk_sizes, query, top_k=3):\n",
    "    query_embedding = model.encode(query)\n",
    "    \n",
    "    for size in chunk_sizes:\n",
    "        \n",
    "        print(f\"\\nChunk size: {size} characters\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        chunks = [\n",
    "            document[i:i+ size] for i in range(0, len(document), size)\n",
    "        ]\n",
    "        print(f\"Number of chunks for {size} characters: {len(chunks)}\")\n",
    "\n",
    "        doc_embeddings = model.encode(chunks)\n",
    "        scores = [cosine_similarity(doc_embeddings, query_embedding)[0]]\n",
    "\n",
    "        results = sorted(zip(chunks, scores), key=lambda x:x[1], reverse= True)[:top_k]\n",
    "\n",
    "        for rank, (chunk, score) in enumerate(results, 1):\n",
    "            \n",
    "            print(f\"{rank}. (Score: {score:.3f})\")\n",
    "            print(chunk.strip())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d35fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk size: 100 characters\n",
      "--------------------------------------------------------------------------------\n",
      "Number of chunks for 100 characters: 16\n",
      "1. (Score: 0.123)\n",
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
      "the natural i\n",
      "\n",
      "Chunk size: 200 characters\n",
      "--------------------------------------------------------------------------------\n",
      "Number of chunks for 200 characters: 8\n",
      "1. (Score: 0.176)\n",
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
      "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
      "the field as the study of i\n",
      "\n",
      "Chunk size: 400 characters\n",
      "--------------------------------------------------------------------------------\n",
      "Number of chunks for 400 characters: 4\n",
      "1. (Score: 0.327)\n",
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
      "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
      "the field as the study of intelligent agents: any device that perceives its environment\n",
      "and takes actions that maximize its chance of successfully achieving its goals.\n",
      "\n",
      "Machine learning is a subset of artificial intelligence th\n"
     ]
    }
   ],
   "source": [
    "chunk_sizes = [100, 200, 400]\n",
    "query = \"What is machine learning?\"\n",
    "\n",
    "chunk_embed_retrieve(document, chunk_sizes, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4ff0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# # # Load SentenceTransformer model\n",
    "# # model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# # Short document\n",
    "# document = \"\"\"\n",
    "# Machine learning is a field of artificial intelligence that focuses on enabling computers\n",
    "# to learn from data without being explicitly programmed. It is widely used in applications\n",
    "# such as recommendation systems, image recognition, natural language processing, and fraud\n",
    "# detection. Machine learning models improve their performance as they are exposed to more data.\n",
    "# \"\"\"\n",
    "\n",
    "# def chunk_embed_and_retrieve(document, chunk_sizes, query, top_k=3):\n",
    "#     \"\"\"\n",
    "#     Chunks a document using different chunk sizes, embeds the chunks,\n",
    "#     and retrieves top-k relevant chunks for a query.\n",
    "#     \"\"\"\n",
    "\n",
    "#     query_embedding = model.encode(query)\n",
    "\n",
    "#     for size in chunk_sizes:\n",
    "#         print(f\"\\nðŸ”¹ Chunk Size: {size} characters\")\n",
    "#         print(\"-\" * 60)\n",
    "\n",
    "#         # Step 1: Chunking\n",
    "#         chunks = [\n",
    "#             document[i:i + size]\n",
    "#             for i in range(0, len(document), size)\n",
    "#         ]\n",
    "\n",
    "#         # Step 2: Create embeddings\n",
    "#         chunk_embeddings = model.encode(chunks)\n",
    "\n",
    "#         # Step 3: Similarity search\n",
    "#         scores = [cosine_similarity(chunk_embeddings, query_embedding)[0]]\n",
    "\n",
    "#         # Step 4: Retrieve top-k chunks\n",
    "#         top_results = sorted(\n",
    "#             zip(chunks, scores),\n",
    "#             key=lambda x: x[1],\n",
    "#             reverse=True\n",
    "#         )[:top_k]\n",
    "\n",
    "#         for rank, (chunk, score) in enumerate(top_results, start=1):\n",
    "#             print(f\"\\nRank {rank} | Score: {score:.4f}\")\n",
    "#             print(chunk.strip())\n",
    "\n",
    "\n",
    "# # Run for all chunk sizes\n",
    "# chunk_sizes = [100, 200, 400]\n",
    "# query = \"What is machine learning?\"\n",
    "\n",
    "# chunk_embed_and_retrieve(document, chunk_sizes, query)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
